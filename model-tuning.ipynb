{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "\n",
    "This notebook will be dedicated to tuning the following models:\n",
    "1. Logistic Regression\n",
    "2. Gradient Boosting Trees\n",
    "3. GRU\n",
    "4. LSTM\n",
    "5. Transformers\n",
    "\n",
    "Note, due to computational restraints, I won't be able to perform an exhaustive search. However, I will tune the parameters slightly to see if I can improve model performance and minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from preprocessing import Preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GRU, LSTM, Embedding, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformer import Transformer\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for monitoring the model metrics\n",
    "training_metrics = []\n",
    "validation_metrics = []\n",
    "\n",
    "# Creating a function that returns the metrics\n",
    "def get_metrics(truth,predictions):\n",
    "    f1 = f1_score(truth,predictions)\n",
    "    precision = precision_score(truth,predictions)\n",
    "    recall = recall_score(truth,predictions)\n",
    "    accuracy = accuracy_score(truth,predictions)\n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Models\n",
    "\n",
    "For Logistic Regression and Gradient Boosting, I need to leverage the Bag-of-Words preprocessing approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "training = pd.read_csv('data/bag_of_words_training.csv')\n",
    "testing = pd.read_csv('data/bag_of_words_testing.csv')\n",
    "\n",
    "# Splitting testing data into validation\n",
    "validation, testing = train_test_split(testing,test_size=0.2,random_state=42,shuffle=True,stratify=testing['Target'])\n",
    "validation.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Splitting data into X & y\n",
    "train_x = training.drop(['ID','Target','Keyword'],axis=1)\n",
    "train_y = training['Target'].values\n",
    "valid_x = validation.drop(['ID','Target','Keyword'],axis=1)\n",
    "valid_y = validation['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a Randomized Search on the Logistic Regression Model\n",
    "logReg = LogisticRegression(penalty='l2',random_state=42,max_iter=1500,tol=0.0001)\n",
    "param_grid = {'C':np.random.uniform(low=0.01,high=2.0,size=100)}\n",
    "search = RandomizedSearchCV(logReg,param_grid,n_iter=100,scoring='f1',refit=True,cv=5,random_state=42)\n",
    "search.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the best model\n",
    "tuned_log_reg = search.best_estimator_\n",
    "tuned_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model on the Training Data and Validation Data\n",
    "training_predictions = tuned_log_reg.predict(train_x)\n",
    "validation_predictions = tuned_log_reg.predict(valid_x)\n",
    "train_metrics = get_metrics(train_y,training_predictions)\n",
    "valid_metrics = get_metrics(valid_y,validation_predictions)\n",
    "train_metrics_df = {'Name':'Logistic Regression','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "valid_metrics_df = {'Name':'Logistic Regression','F1':valid_metrics[0],'Precision':valid_metrics[1],'Recall':valid_metrics[2],'Accuracy':valid_metrics[3]}\n",
    "\n",
    "training_metrics.append(train_metrics_df)\n",
    "validation_metrics.append(valid_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the gradient boosting model\n",
    "catboost_clf = CatBoostClassifier(iterations=1500,loss_function='Logloss',random_state=42,early_stopping_rounds=10,eval_metric='F1')\n",
    "param_grid = {'learning_rate':np.random.uniform(0.0001,0.5,100),'depth':np.random.randint(1,16,size=7),\n",
    "              'l2_leaf_reg':np.random.uniform(0.5,5,100),'min_data_in_leaf':np.random.randint(5,50,size=10)}\n",
    "search = catboost_clf.randomized_search(param_grid,train_x,train_y,cv=3,n_iter=15,refit=True,shuffle=True,stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the parameters\n",
    "catboost_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model on the Training Data and Validation Data\n",
    "training_predictions = catboost_clf.predict(train_x)\n",
    "validation_predictions = catboost_clf.predict(valid_x)\n",
    "train_metrics = get_metrics(train_y,training_predictions)\n",
    "valid_metrics = get_metrics(valid_y,validation_predictions)\n",
    "train_metrics_df = {'Name':'Gradient Boosting','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "valid_metrics_df = {'Name':'Gradient Boosting','F1':valid_metrics[0],'Precision':valid_metrics[1],'Recall':valid_metrics[2],'Accuracy':valid_metrics[3]}\n",
    "\n",
    "training_metrics.append(train_metrics_df)\n",
    "validation_metrics.append(valid_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Models\n",
    "\n",
    "Now, I need to prepare the data into a sequence format for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "raw_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Splitting the data into training, validation, and testing\n",
    "training, testing = train_test_split(raw_train,test_size=0.2,random_state=42,shuffle=True,stratify=raw_train['target'])\n",
    "validation, testing = train_test_split(testing,test_size=0.2,random_state=42,shuffle=True,stratify=testing['target'])\n",
    "training.reset_index(drop=True,inplace=True)\n",
    "validation.reset_index(drop=True,inplace=True)\n",
    "testing.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Splitting data into X & Y\n",
    "train_x = training.drop(['target'],axis=1)\n",
    "train_y = training['target'].values\n",
    "valid_x = validation.drop(['target'],axis=1)\n",
    "valid_y = validation['target'].values\n",
    "\n",
    "# Getting the preprocessed text\n",
    "preprocessor = Preprocessing()\n",
    "preprocessed_train_x = preprocessor.preprocess_data(train_x)\n",
    "preprocessed_valid_x = preprocessor.preprocess_data(valid_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data to (number of examples, 57, 1000)\n",
    "training_X = []\n",
    "valid_X = []\n",
    "\n",
    "# Opening the vocabulary and marking 1 to indicate the word\n",
    "with open('mappers/word2index.json') as file:\n",
    "    vocabulary = json.load(file)\n",
    "\n",
    "    # Iterating through the training\n",
    "    for sentence_index in range(0,len(preprocessed_train_x)):\n",
    "        sentence_convert = [1001] * 57\n",
    "        for word_index in range(0,len(preprocessed_train_x[sentence_index])):\n",
    "            # If the word is in the vocab, get the index\n",
    "            word = preprocessed_train_x[sentence_index][word_index]\n",
    "            if word in vocabulary.keys():\n",
    "                sentence_convert[word_index] = vocabulary[word]\n",
    "            else:\n",
    "                sentence_convert[word_index] = 1000\n",
    "        \n",
    "        training_X.append(sentence_convert)\n",
    "    \n",
    "    # Iterating through the validation\n",
    "    for sentence_index in range(0,len(preprocessed_valid_x)):\n",
    "        sentence_convert = [1001] * 57\n",
    "        for word_index in range(0,len(preprocessed_valid_x[sentence_index])):\n",
    "            # If the word is in the vocab, get the index\n",
    "            word = preprocessed_valid_x[sentence_index][word_index]\n",
    "            if word in vocabulary.keys():\n",
    "                sentence_convert[word_index] = vocabulary[word]\n",
    "            else:\n",
    "                sentence_convert[word_index] = 1000\n",
    "\n",
    "        valid_X.append(sentence_convert)\n",
    "\n",
    "training_X = np.array(training_X)\n",
    "valid_X = np.array(valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to build the GRU model\n",
    "def build_gru(embedding_dim=50,hidden_units=50,dropout_rate=0.2,lr=0.001):\n",
    "    gru_clf = Sequential()\n",
    "    gru_clf.add(Embedding(input_dim=1002,output_dim=embedding_dim,input_length=training_X.shape[1]))\n",
    "    gru_clf.add(Dropout(rate=dropout_rate))\n",
    "    gru_clf.add(GRU(units=hidden_units,activation='tanh',recurrent_activation='sigmoid',bias_initializer='ones',return_sequences=False))\n",
    "    gru_clf.add(BatchNormalization())\n",
    "    gru_clf.add(Dropout(rate=dropout_rate))\n",
    "    gru_clf.add(Dense(1,activation='sigmoid',bias_initializer='ones'))\n",
    "\n",
    "    # Compiling the model\n",
    "    loss_function = 'binary_crossentropy'\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    gru_clf.compile(optimizer,loss_function)\n",
    "\n",
    "    # returning the model\n",
    "    return gru_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikeras to wrap the model into a scikit-learn classifier\n",
    "gru_model = KerasClassifier(build_gru,embedding_dim=50,hidden_units=50,dropout_rate=0.2,lr=0.001)\n",
    "param_grid = {'embedding_dim':np.random.randint(50,500,size=100),'hidden_units':np.random.randint(50,500,size=100),\n",
    "              'dropout_rate':np.random.uniform(0,0.5,size=50),'lr':np.random.uniform(0.00001,0.03,size=100)}\n",
    "\n",
    "# Performing randomized search on the model\n",
    "clf = RandomizedSearchCV(gru_model,param_grid,n_iter=10,scoring='f1',refit=True,cv=3,random_state=42,verbose=3)\n",
    "search = clf.fit(training_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the best hyperparameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "best_gru = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model on the Training Data and Validation Data\n",
    "training_predictions = best_gru.predict(training_X)\n",
    "validation_predictions = best_gru.predict(valid_X)\n",
    "train_metrics = get_metrics(train_y,training_predictions)\n",
    "valid_metrics = get_metrics(valid_y,validation_predictions)\n",
    "train_metrics_df = {'Name':'GRU','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "valid_metrics_df = {'Name':'GRU','F1':valid_metrics[0],'Precision':valid_metrics[1],'Recall':valid_metrics[2],'Accuracy':valid_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics.append(train_metrics_df)\n",
    "validation_metrics.append(valid_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to build the LSTM model\n",
    "def build_lstm(embedding_dim=50,hidden_units=50,dropout_rate=0.2,lr=0.001):\n",
    "    lstm_clf = Sequential()\n",
    "    lstm_clf.add(Embedding(input_dim=1002,output_dim=embedding_dim,input_length=training_X.shape[1]))\n",
    "    lstm_clf.add(Dropout(rate=dropout_rate))\n",
    "    lstm_clf.add(LSTM(units=hidden_units,activation='tanh',recurrent_activation='sigmoid',return_sequences=False))\n",
    "    lstm_clf.add(BatchNormalization())\n",
    "    lstm_clf.add(Dense(1,activation='sigmoid',bias_initializer='ones'))\n",
    "    loss_function = 'binary_crossentropy'\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    lstm_clf.compile(optimizer,loss_function)\n",
    "\n",
    "    # returning the model\n",
    "    return lstm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scikeras to wrap the model into a scikit-learn classifier\n",
    "lstm_model = KerasClassifier(build_lstm,embedding_dim=50,hidden_units=50,dropout_rate=0.2,lr=0.001)\n",
    "param_grid = {'embedding_dim':np.random.randint(50,500,size=100),'hidden_units':np.random.randint(50,500,size=100),\n",
    "              'dropout_rate':np.random.uniform(0,0.5,size=50),'lr':np.random.uniform(0.00001,0.03,size=100)}\n",
    "\n",
    "# Performing randomized search on the model\n",
    "clf = RandomizedSearchCV(lstm_model,param_grid,n_iter=10,scoring='f1',refit=True,cv=3,random_state=42,verbose=3)\n",
    "search = clf.fit(training_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the best hyperparameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "best_lstm = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model on the Training Data and Validation Data\n",
    "training_predictions = best_lstm.predict(training_X)\n",
    "validation_predictions = best_lstm.predict(valid_X)\n",
    "train_metrics = get_metrics(train_y,training_predictions)\n",
    "valid_metrics = get_metrics(valid_y,validation_predictions)\n",
    "train_metrics_df = {'Name':'LSTM','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "valid_metrics_df = {'Name':'LSTM','F1':valid_metrics[0],'Precision':valid_metrics[1],'Recall':valid_metrics[2],'Accuracy':valid_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics.append(train_metrics_df)\n",
    "validation_metrics.append(valid_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "Won't do randomized search CV since that could take some time. Will just add some dropout and train model to see performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dataset for PyTorch\n",
    "train_X = torch.from_numpy(np.array(training_X))\n",
    "valid_X = torch.from_numpy(np.array(valid_X))\n",
    "train_y = torch.from_numpy(train_y)\n",
    "valid_y = torch.from_numpy(valid_y)\n",
    "\n",
    "training_dataset = TensorDataset(train_X,train_y)\n",
    "validation_dataset = TensorDataset(valid_X,valid_y)\n",
    "\n",
    "# Storing the training and validation data in DataLoaders\n",
    "training_loader = DataLoader(training_dataset,batch_size=32,shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for the training loop\n",
    "def training_loop(model,loss_fn,optimizer,training_data):\n",
    "    size = len(training_data.dataset)\n",
    "    model.train() # Setting the model to training mode\n",
    "\n",
    "    # Iterating through the batches\n",
    "    for batch , (X,y) in enumerate(training_data):\n",
    "        # Compute the predictions\n",
    "        pred = model(X)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        # Calculate the derivatives (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Take a step with the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Printing out the progress for every 20 batches\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f'loss :{loss} {round(current/size,2)*100}% Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Model\n",
    "model = Transformer()\n",
    "epochs = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}\\n-------------------------------')\n",
    "    training_loop(model,loss_function,optimizer,training_loader)\n",
    "    training_pred = model(train_X)\n",
    "    loss = loss_function(training_pred,train_y)\n",
    "    history.append(loss.item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions\n",
    "training_predictions = np.argmax(model(train_X).detach().numpy(),axis=1)\n",
    "validation_predictions = np.argmax(model(valid_X).detach().numpy(),axis=1)\n",
    "train_metrics = get_metrics(train_y,np.rint(training_predictions))\n",
    "valid_metrics = get_metrics(valid_y,np.rint(validation_predictions))\n",
    "train_metrics_df = {'Name':'Transformer','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "valid_metrics_df = {'Name':'Transformer','F1':valid_metrics[0],'Precision':valid_metrics[1],'Recall':valid_metrics[2],'Accuracy':valid_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics.append(train_metrics_df)\n",
    "validation_metrics.append(valid_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the metrics to dataframe for analysis\n",
    "training_metrics_df = pd.DataFrame(training_metrics)\n",
    "validation_metrics_df = pd.DataFrame(validation_metrics)\n",
    "print('Training Metrics:')\n",
    "print(training_metrics_df)\n",
    "print()\n",
    "print('Validation Metrics:') \n",
    "print(validation_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "march-madness-mania",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
