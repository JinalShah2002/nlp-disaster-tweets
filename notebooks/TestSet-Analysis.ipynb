{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Analysis\n",
    "\n",
    "This notebook will run the tuned models on the test sets and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('/Users/jinalshah/Jinal/Projects/nlp-disaster-tweets/src')\n",
    "\n",
    "from preprocessing import Preprocessing\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_metrics = []\n",
    "training_metrics = []\n",
    "\n",
    "# Creating a function that returns the metrics\n",
    "def get_metrics(truth,predictions):\n",
    "    f1 = f1_score(truth,predictions)\n",
    "    precision = precision_score(truth,predictions)\n",
    "    recall = recall_score(truth,predictions)\n",
    "    accuracy = accuracy_score(truth,predictions)\n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "testing = pd.read_csv('../inputs/bag_of_words_testing.csv')\n",
    "training = pd.read_csv('../inputs/bag_of_words_training.csv')\n",
    "\n",
    "# Splitting data into X & y\n",
    "train_x = training.drop(['ID','Target','Keyword'],axis=1)\n",
    "train_y = training['Target'].values\n",
    "test_x = testing.drop(['ID','Target','Keyword'],axis=1)\n",
    "test_y = testing['Target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinalshah/Jinal/Projects/nlp-disaster-tweets/.conda/lib/python3.11/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Getting the model\n",
    "logReg = pickle.load(open('../models/logistic-regression.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "test_predictions = logReg.predict(test_x)\n",
    "train_predictions = logReg.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcutating the score\n",
    "train_metrics = get_metrics(train_y,train_predictions)\n",
    "train_metrics_df = {'Name':'Logistic Regression','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "test_metrics = get_metrics(test_y,test_predictions)\n",
    "test_metrics_df = {'Name':'Logistic Regression','F1':test_metrics[0],'Precision':test_metrics[1],'Recall':test_metrics[2],'Accuracy':test_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Logistic Regression',\n",
       " 'F1': 0.8074534161490682,\n",
       " 'Precision': 0.8205128205128205,\n",
       " 'Recall': 0.7948032097821933,\n",
       " 'Accuracy': 0.8371100164203612}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the train metrics\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Logistic Regression',\n",
       " 'F1': 0.7713625866050807,\n",
       " 'Precision': 0.7767441860465116,\n",
       " 'Recall': 0.7660550458715596,\n",
       " 'Accuracy': 0.8049901510177282}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the test metrics\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the results to the list\n",
    "training_metrics.append(train_metrics_df)\n",
    "testing_metrics.append(test_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "catboost_clf = pickle.load(open('../models/gradient-boosting.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "test_predictions = catboost_clf.predict(test_x)\n",
    "train_predictions = catboost_clf.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcutating the score\n",
    "train_metrics = get_metrics(train_y,train_predictions)\n",
    "train_metrics_df = {'Name':'Gradient Boosting','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "test_metrics = get_metrics(test_y,test_predictions)\n",
    "test_metrics_df = {'Name':'Gradient Boosting','F1':test_metrics[0],'Precision':test_metrics[1],'Recall':test_metrics[2],'Accuracy':test_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Gradient Boosting',\n",
       " 'F1': 0.7834370139968897,\n",
       " 'Precision': 0.7973882073605065,\n",
       " 'Recall': 0.7699656094764998,\n",
       " 'Accuracy': 0.8170771756978653}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the train metrics\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Gradient Boosting',\n",
       " 'F1': 0.7415384615384615,\n",
       " 'Precision': 0.7461300309597523,\n",
       " 'Recall': 0.7370030581039755,\n",
       " 'Accuracy': 0.7793827971109653}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the metrics\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the results to the list\n",
    "training_metrics.append(train_metrics_df)\n",
    "testing_metrics.append(test_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jinalshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the data\n",
    "raw_train = pd.read_csv('../inputs/train.csv')\n",
    "\n",
    "# Getting the testing data\n",
    "training, testing = train_test_split(raw_train,test_size=0.2,random_state=42,shuffle=True,stratify=raw_train['target'])\n",
    "training.reset_index(drop=True,inplace=True)\n",
    "testing.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Splitting data into X & Y\n",
    "train_x = training.drop(['target'],axis=1)\n",
    "train_y = training['target'].values\n",
    "test_x = testing.drop(['target'],axis=1)\n",
    "test_y = testing['target'].values\n",
    "\n",
    "# Getting the preprocessed text\n",
    "preprocessor = Preprocessing()\n",
    "preprocessed_train_x = preprocessor.preprocess_data(train_x)\n",
    "preprocessed_test_x = preprocessor.preprocess_data(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data to (number of examples, 57, 1000)\n",
    "training_X = []\n",
    "testing_X = []\n",
    "\n",
    "# Opening the vocabulary and marking 1 to indicate the word\n",
    "with open('../mappers/word2index.json') as file:\n",
    "    vocabulary = json.load(file)\n",
    "\n",
    "    # Iterating through the testing\n",
    "    for sentence_index in range(0,len(preprocessed_test_x)):\n",
    "        sentence_convert = [1001] * 57\n",
    "        for word_index in range(0,len(preprocessed_test_x[sentence_index])):\n",
    "            # If the word is in the vocab, get the index\n",
    "            word = preprocessed_test_x[sentence_index][word_index]\n",
    "            if word in vocabulary.keys():\n",
    "                sentence_convert[word_index] = vocabulary[word]\n",
    "            else:\n",
    "                sentence_convert[word_index] = 1000\n",
    "\n",
    "        testing_X.append(sentence_convert)\n",
    "    \n",
    "    # Iterating through the training\n",
    "    for sentence_index in range(0,len(preprocessed_train_x)):\n",
    "        sentence_convert = [1001] * 57\n",
    "        for word_index in range(0,len(preprocessed_train_x[sentence_index])):\n",
    "            # If the word is in the vocab, get the index\n",
    "            word = preprocessed_train_x[sentence_index][word_index]\n",
    "            if word in vocabulary.keys():\n",
    "                sentence_convert[word_index] = vocabulary[word]\n",
    "            else:\n",
    "                sentence_convert[word_index] = 1000\n",
    "\n",
    "        training_X.append(sentence_convert)\n",
    "\n",
    "testing_X = np.array(testing_X)\n",
    "training_X = np.array(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "# Note, when loading keras models make sure the versions \n",
    "# match-up (version of keras model when saving and the version of keras in the environment)\n",
    "gru_model = keras.models.load_model('../models/gru.keras',compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 13ms/step\n",
      "191/191 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "test_predictions = gru_model.predict(testing_X)\n",
    "train_predictions = gru_model.predict(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcutating the score and adding to the array\n",
    "train_metrics = get_metrics(train_y,np.rint(train_predictions))\n",
    "train_metrics_df = {'Name':'GRU','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "test_metrics = get_metrics(test_y,np.rint(test_predictions))\n",
    "test_metrics_df = {'Name':'GRU','F1':test_metrics[0],'Precision':test_metrics[1],'Recall':test_metrics[2],'Accuracy':test_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'GRU',\n",
       " 'F1': 0.8098484848484848,\n",
       " 'Precision': 0.8028539241457003,\n",
       " 'Recall': 0.8169659915934276,\n",
       " 'Accuracy': 0.8351395730706076}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the train metrics\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'GRU',\n",
       " 'F1': 0.7540983606557378,\n",
       " 'Precision': 0.7354651162790697,\n",
       " 'Recall': 0.7737003058103975,\n",
       " 'Accuracy': 0.783322390019698}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the metrics\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the results to the list\n",
    "training_metrics.append(train_metrics_df)\n",
    "testing_metrics.append(test_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "# Note, when loading keras models make sure the versions \n",
    "# match-up (version of keras model when saving and the version of keras in the environment)\n",
    "lstm_model = keras.models.load_model('../models/lstm.keras',compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 10ms/step\n",
      "191/191 [==============================] - 2s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "test_predictions = lstm_model.predict(testing_X)\n",
    "train_predictions = lstm_model.predict(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring\n",
    "train_metrics = get_metrics(train_y,np.rint(train_predictions))\n",
    "train_metrics_df = {'Name':'LSTM','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "test_metrics = get_metrics(test_y,np.rint(test_predictions))\n",
    "test_metrics_df = {'Name':'LSTM','F1':test_metrics[0],'Precision':test_metrics[1],'Recall':test_metrics[2],'Accuracy':test_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'LSTM',\n",
       " 'F1': 0.8064516129032259,\n",
       " 'Precision': 0.7918968692449355,\n",
       " 'Recall': 0.8215513947267864,\n",
       " 'Accuracy': 0.8305418719211822}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the train metrics\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'LSTM',\n",
       " 'F1': 0.7559171597633136,\n",
       " 'Precision': 0.7320916905444126,\n",
       " 'Recall': 0.7813455657492355,\n",
       " 'Accuracy': 0.783322390019698}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the metrics\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the results to the list\n",
    "training_metrics.append(train_metrics_df)\n",
    "testing_metrics.append(test_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Embedding(1002, 200)\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       "  (layernorm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "  (atten_output): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (final_atten_output): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (layernorm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "  (clf_output_one): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (output): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the model\n",
    "transformer = Transformer(embed_dim=200,heads=4,dropout_rate=0.4)\n",
    "transformer.load_state_dict(torch.load('../models/transformers200-4-0-4.pt'))\n",
    "transformer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions\n",
    "test_predictions = transformer(torch.from_numpy(testing_X))\n",
    "train_predictions = transformer(torch.from_numpy(training_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcutating the score and adding to the array\n",
    "train_metrics = get_metrics(train_y,np.argmax(train_predictions.detach().numpy(),axis=1))\n",
    "train_metrics_df = {'Name':'Transformer','F1':train_metrics[0],'Precision':train_metrics[1],'Recall':train_metrics[2],'Accuracy':train_metrics[3]}\n",
    "test_metrics = get_metrics(test_y,np.argmax(test_predictions.detach().numpy(),axis=1))\n",
    "test_metrics_df = {'Name':'Transformer','F1':test_metrics[0],'Precision':test_metrics[1],'Recall':test_metrics[2],'Accuracy':test_metrics[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Transformer',\n",
       " 'F1': 0.7769039735099339,\n",
       " 'Precision': 0.8474040632054176,\n",
       " 'Recall': 0.7172334734428735,\n",
       " 'Accuracy': 0.8229885057471265}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the train metrics\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Transformer',\n",
       " 'F1': 0.7323481116584564,\n",
       " 'Precision': 0.7907801418439716,\n",
       " 'Recall': 0.6819571865443425,\n",
       " 'Accuracy': 0.7859487852921865}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the metrics\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the results to the list\n",
    "training_metrics.append(train_metrics_df)\n",
    "testing_metrics.append(test_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "                  Name        F1  Precision    Recall  Accuracy\n",
      "0  Logistic Regression  0.807453   0.820513  0.794803  0.837110\n",
      "1    Gradient Boosting  0.783437   0.797388  0.769966  0.817077\n",
      "2                  GRU  0.809848   0.802854  0.816966  0.835140\n",
      "3                 LSTM  0.806452   0.791897  0.821551  0.830542\n",
      "4          Transformer  0.776904   0.847404  0.717233  0.822989\n",
      "Testing Metrics:\n",
      "                  Name        F1  Precision    Recall  Accuracy\n",
      "0  Logistic Regression  0.771363   0.776744  0.766055  0.804990\n",
      "1    Gradient Boosting  0.741538   0.746130  0.737003  0.779383\n",
      "2                  GRU  0.754098   0.735465  0.773700  0.783322\n",
      "3                 LSTM  0.755917   0.732092  0.781346  0.783322\n",
      "4          Transformer  0.732348   0.790780  0.681957  0.785949\n"
     ]
    }
   ],
   "source": [
    "# Viewing the metrics in a dataframe\n",
    "training_metrics_df = pd.DataFrame(training_metrics)\n",
    "testing_metrics_df = pd.DataFrame(testing_metrics)\n",
    "\n",
    "print('Training Metrics:')\n",
    "print(training_metrics_df)\n",
    "\n",
    "print('Testing Metrics:')\n",
    "print(testing_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036091</td>\n",
       "      <td>0.043769</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041899</td>\n",
       "      <td>0.051258</td>\n",
       "      <td>0.032963</td>\n",
       "      <td>0.037694</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055750</td>\n",
       "      <td>0.067389</td>\n",
       "      <td>0.043266</td>\n",
       "      <td>0.051817</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050534</td>\n",
       "      <td>0.059805</td>\n",
       "      <td>0.040206</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044556</td>\n",
       "      <td>0.056624</td>\n",
       "      <td>0.035276</td>\n",
       "      <td>0.037040</td>\n",
       "      <td>Transformer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1  Precision    Recall  Accuracy                 Name\n",
       "0  0.036091   0.043769  0.028748  0.032120  Logistic Regression\n",
       "1  0.041899   0.051258  0.032963  0.037694    Gradient Boosting\n",
       "2  0.055750   0.067389  0.043266  0.051817                  GRU\n",
       "3  0.050534   0.059805  0.040206  0.047219                 LSTM\n",
       "4  0.044556   0.056624  0.035276  0.037040          Transformer"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking overfitting\n",
    "overfit = training_metrics_df.drop('Name',axis=1) - testing_metrics_df.drop('Name',axis=1)\n",
    "overfit['Name'] = training_metrics_df['Name']\n",
    "overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the metrics to a csv file for future reference\n",
    "training_metrics_df.to_csv('../performances/training_metrics.csv',index=False)\n",
    "testing_metrics_df.to_csv('../performances/testing_metrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like Logistic Regression is the best model in this case! I am going to submit predictions from all 5 models to see how they stack up.\n",
    "\n",
    "Hypothesis: Model Performance will follow this trend:\n",
    "1) Logistic Regression\n",
    "2) Gradient Boosting\n",
    "3) Transformer\n",
    "4) LSTM\n",
    "5) GRU\n",
    "\n",
    "Actual Trend:\n",
    "1. Transformer - 0.7768\n",
    "2. Logistic Regression - 0.768\n",
    "3. GRU - 0.76739\n",
    "4. LSTM - 075758\n",
    "5. Gradient Boosting - 0.75758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the submission data\n",
    "sub_data = pd.read_csv('../inputs/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jinalshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Getting the preprocessed sentences\n",
    "preprocessor = Preprocessing()\n",
    "cleaned_sub_tweets = preprocessor.preprocess_data(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary with the counts of each word in each tweet\n",
    "word_counts = []\n",
    "for sentence in cleaned_sub_tweets:\n",
    "    sentence_tokens = {}\n",
    "    for word in sentence:\n",
    "        if word in sentence_tokens.keys():\n",
    "            temp = sentence_tokens[word] + 1\n",
    "            sentence_tokens[word] = temp\n",
    "        else:\n",
    "            sentence_tokens[word] = 1\n",
    "    word_counts.append(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>11-year-old</th>\n",
       "      <th>12</th>\n",
       "      <th>12000</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>16yr</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zone</th>\n",
       "      <th>~</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      +  10  11  11-year-old  12  12000  13  15  16  16yr  ...  year  years  \\\n",
       "0     0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "1     0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "2     0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "3     0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "4     0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "...  ..  ..  ..          ...  ..    ...  ..  ..  ..   ...  ...   ...    ...   \n",
       "3258  0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "3259  0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "3260  0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "3261  0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "3262  0   0   0            0   0      0   0   0   0     0  ...     0      0   \n",
       "\n",
       "      yes  yet  york  young  youth  youtube  zone  ~  \n",
       "0       0    0     0      0      0        0     0  0  \n",
       "1       0    0     0      0      0        0     0  0  \n",
       "2       0    0     0      0      0        0     0  0  \n",
       "3       0    0     0      0      0        0     0  0  \n",
       "4       0    0     0      0      0        0     0  0  \n",
       "...   ...  ...   ...    ...    ...      ...   ... ..  \n",
       "3258    0    0     0      0      0        0     0  0  \n",
       "3259    0    0     0      0      0        0     0  0  \n",
       "3260    0    0     0      0      0        0     0  0  \n",
       "3261    0    0     0      0      0        0     0  0  \n",
       "3262    0    0     0      0      0        0     0  0  \n",
       "\n",
       "[3263 rows x 1000 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the bag of words vector for each example\n",
    "bag_of_words = []\n",
    "\n",
    "with open('../mappers/word2index.json') as file:\n",
    "    vocabulary = json.load(file)\n",
    "    \n",
    "    for index in range(0,len(word_counts)):\n",
    "        vector = {}\n",
    "\n",
    "        for word in vocabulary.keys():\n",
    "            if word in word_counts[index].keys():\n",
    "                vector[word] = word_counts[index][word]\n",
    "            else:\n",
    "                vector[word] = 0\n",
    "        bag_of_words.append(vector)\n",
    "\n",
    "sub_bow_df = pd.DataFrame(bag_of_words)\n",
    "sub_bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the logistic regression predictions\n",
    "pred_logreg = logReg.predict(sub_bow_df)\n",
    "pred_logreg_df = pd.DataFrame()\n",
    "pred_logreg_df['id'] = sub_data['id']\n",
    "pred_logreg_df['target'] = pred_logreg\n",
    "\n",
    "# Saving the dataframe\n",
    "pred_logreg_df.to_csv('../predictions/pred_logreg.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the gradient boosting predictions\n",
    "pred_gb = catboost_clf.predict(sub_bow_df)\n",
    "pred_gb_df = pd.DataFrame()\n",
    "pred_gb_df['id'] = sub_data['id']\n",
    "pred_gb_df['target'] = pred_gb\n",
    "\n",
    "# Saving the dataframe\n",
    "pred_gb_df.to_csv('../predictions/pred_gb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data to (number of examples, 57, 1000)\n",
    "submission_input = []\n",
    "\n",
    "# Opening the vocabulary and marking 1 to indicate the word\n",
    "with open('../mappers/word2index.json') as file:\n",
    "    vocabulary = json.load(file)\n",
    "\n",
    "    # Iterating through the testing\n",
    "    for sentence_index in range(0,len(cleaned_sub_tweets)):\n",
    "        sentence_convert = [1001] * 57\n",
    "        for word_index in range(0,len(cleaned_sub_tweets[sentence_index])):\n",
    "            # If the word is in the vocab, get the index\n",
    "            word = cleaned_sub_tweets[sentence_index][word_index]\n",
    "            if word in vocabulary.keys():\n",
    "                sentence_convert[word_index] = vocabulary[word]\n",
    "            else:\n",
    "                sentence_convert[word_index] = 1000\n",
    "\n",
    "        submission_input.append(sentence_convert)\n",
    "submission_input = np.array(submission_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Getting the gru predictions\n",
    "pred_gru = gru_model.predict(submission_input)\n",
    "pred_gru_df = pd.DataFrame()\n",
    "pred_gru_df['id'] = sub_data['id']\n",
    "pred_gru_df['target'] = np.rint(pred_gru)\n",
    "pred_gru_df['target'] = pred_gru_df['target'].astype(int)\n",
    "\n",
    "# Saving the dataframe\n",
    "pred_gru_df.to_csv('../predictions/pred_gru.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30/102 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Getting the lstm predictions\n",
    "pred_lstm = lstm_model.predict(submission_input)\n",
    "pred_lstm_df = pd.DataFrame()\n",
    "pred_lstm_df['id'] = sub_data['id']\n",
    "pred_lstm_df['target'] = np.rint(pred_lstm)\n",
    "pred_lstm_df['target'] = pred_lstm_df['target'].astype(int)\n",
    "\n",
    "# Saving the dataframe\n",
    "pred_lstm_df.to_csv('../predictions/pred_lstm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the transformer predictions\n",
    "pred_transformer= transformer(torch.from_numpy(submission_input))\n",
    "pred_transformer_df = pd.DataFrame()\n",
    "pred_transformer_df['id'] = sub_data['id']\n",
    "pred_transformer_df['target'] = np.argmax(pred_transformer.detach().numpy(),axis=1)\n",
    "\n",
    "# Saving the dataframe\n",
    "pred_transformer_df.to_csv('../predictions/pred_transformer.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
